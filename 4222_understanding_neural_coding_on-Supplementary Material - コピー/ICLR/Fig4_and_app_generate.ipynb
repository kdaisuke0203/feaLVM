{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import time\n",
    "from scipy.stats import pearsonr\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "\n",
    "def eval_lats(pred, target, res=1000):\n",
    "    errs = np.zeros((2, res))\n",
    "    for i in range(2):\n",
    "        for i_s, s in enumerate(np.linspace(0, 2 * np.pi, res)):\n",
    "            newpred = 2 * (0.5 - i) * pred + s\n",
    "            errs[i, i_s] = np.mean(np.arccos(np.cos(newpred - target)))\n",
    "            \n",
    "    i, s = np.unravel_index(errs.argmin(), errs.shape)\n",
    "            \n",
    "    return np.amin(errs), 2 * (0.5 - i), np.linspace(0, 2 * np.pi, res)[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_plot_list(\n",
    "    scale_num_list,\n",
    "    scaling_type, #{'N', 'T'}\n",
    "    model_type, #{'VAE', 'GP', 'mGP'}\n",
    "    feature_type, #{'bump', 'shared', 'separate', 'orig', 'cosyne'}\n",
    "    vae_inference, #{'inf_False_', 'inf_True_', ''}\n",
    "    rate_or_latents, #{'latents', 'rates'}\n",
    "    n_sims=20\n",
    "):  \n",
    "    mean_list = []\n",
    "    var_list = []\n",
    "    \n",
    "    if model_type == 'mGP':\n",
    "        if scaling_type == 'N':\n",
    "            num_train = 1000\n",
    "        elif scaling_type == 'T':\n",
    "            num_neuron_train = 30\n",
    "        for scale_num in scale_num_list:\n",
    "            if scaling_type == 'N':\n",
    "                num_neuron_train = scale_num\n",
    "            elif scaling_type == 'T':\n",
    "                num_train = scale_num\n",
    "            rep_list = []\n",
    "            for rep_num in range(n_sims):\n",
    "                file_name = os.path.join(os.getcwd(), 'results', 'mgplvm_results', 'mgplvm_res_%s_%d_N%d_T%d.p' % (\n",
    "                    feature_type, rep_num, num_neuron_train, num_train))\n",
    "                \n",
    "                with open(file_name, 'rb') as handle:\n",
    "                    stats_ = pickle.load(handle)\n",
    "                \n",
    "                dgf = n_sims - 1\n",
    "                \n",
    "                if rate_or_latents == 'rates':\n",
    "                    corr_rates = []\n",
    "                    for j in np.where(~stats_['neuron_train_ind'])[0]:\n",
    "                        corr_rates.append(pearsonr(stats_['y_test'][j, :], stats_['y_pred'][j, -stats_['y_test'].shape[1]:])[0])\n",
    "\n",
    "                    corr_rates = np.nanmean(corr_rates)\n",
    "                    rep_list.append(corr_rates)\n",
    "                \n",
    "                if rate_or_latents == 'LLH':\n",
    "                    temp = []\n",
    "                    for j in np.where(~stats_['neuron_train_ind'])[0]:\n",
    "                        print(stats_['y_pred'][j, -stats_['y_test'].shape[1]:])\n",
    "                        temp.append(np.sum(stats_['y_pred'][j, -stats_['y_test'].shape[1]:] - stats_['y_test'][j, :] * np.log(stats_['y_pred'][j, -stats_['y_test'].shape[1]:] + 1e-9)))\n",
    "                    \n",
    "                    rep_list.append(np.sum(temp))\n",
    "\n",
    "                \n",
    "                if rate_or_latents == 'latents':\n",
    "                    err, _, _ = eval_lats(stats_['z_pred'][-stats_['z_test'].shape[0]:], stats_['z_test'])\n",
    "                    rep_list.append(err)\n",
    "                \n",
    "            mean_list.append(np.mean((rep_list)))\n",
    "            var_list.append(np.sum(((rep_list) - np.mean((rep_list)))**2)/dgf)\n",
    "                \n",
    "    else:\n",
    "        for scale_num in scale_num_list:\n",
    "            file_name = os.path.join(os.getcwd(), 'results', 'fig2_stats_peakrate_0.5_%s_%s_%s%s_%d.pkl' % (\n",
    "                model_type, feature_type, vae_inference, scaling_type, scale_num))\n",
    "\n",
    "            with open(file_name, 'rb') as handle:\n",
    "                stats_ = pickle.load(handle)\n",
    "\n",
    "            dgf = n_sims - 1\n",
    "\n",
    "            if rate_or_latents == 'rates':\n",
    "                mean_list.append(np.mean((stats_['corr_rates'])))\n",
    "                var_list.append(np.sum(((stats_['corr_rates']) - np.mean((stats_['corr_rates'])))**2)/dgf)\n",
    "\n",
    "            if rate_or_latents == 'LLH':\n",
    "                temp = []\n",
    "                for rep_num in range(n_sims):\n",
    "                    temp.append(np.sum(stats_['y_pred'][rep_num] - stats_['y_test'][rep_num] * np.log(stats_['y_pred'][rep_num] + 1e-9)))\n",
    "                \n",
    "                mean_list.append(np.mean((temp)))\n",
    "                var_list.append(temp)\n",
    "                \n",
    "            if rate_or_latents == 'latents':\n",
    "                temp = []\n",
    "                for i in range(n_sims):\n",
    "                    err, _, _ = eval_lats(stats_['z_pred'][i], stats_['z_test'][i])\n",
    "                    temp.append(err)\n",
    "\n",
    "                mean_list.append(np.mean((temp)))\n",
    "                var_list.append(np.sum(((temp) - np.mean((temp)))**2)/dgf)\n",
    "\n",
    "    return mean_list, var_list, dgf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fig2A():\n",
    "    \n",
    "    T_list = [75, 100, 150, 200, 300, 400, 500, 750, 1000, 2500]\n",
    "    N_list = [10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "        \n",
    "    # All fae models (Table1)\n",
    "    params1 = {\n",
    "        #'mGP-g' : [N_list, 'N', 'mGP', 'orig', '', 'LLH'],\n",
    "        'i-faeLVM-n' : [N_list, 'N', 'VAE', 'separate_flex64', 'inf_True_', 'LLH'],\n",
    "        'i-faeLVM-s' : [N_list, 'N', 'VAE', 'shared_flex', 'inf_True_', 'LLH'],\n",
    "        'i-faeLVM-b' : [N_list, 'N', 'VAE', 'bump', 'inf_True_', 'LLH'],\n",
    "        'faeLVM-n' : [N_list, 'N', 'VAE', 'separate_flex64', 'inf_False_', 'LLH'],\n",
    "        'faeLVM-s' : [N_list, 'N', 'VAE', 'shared_flex', 'inf_False_', 'LLH'],\n",
    "        'faeLVM-b' : [N_list, 'N', 'VAE', 'bump', 'inf_False_', 'LLH']\n",
    "    }\n",
    "    \n",
    "    params2 = {\n",
    "        'i-faeLVM-n' : [N_list, 'N', 'VAE', 'separate_flex64', 'inf_True_', 'latents'],\n",
    "        'i-faeLVM-s' : [N_list, 'N', 'VAE', 'shared_flex', 'inf_True_', 'latents'],\n",
    "        'i-faeLVM-b' : [N_list, 'N', 'VAE', 'bump', 'inf_True_', 'latents'],\n",
    "        'faeLVM-n' : [N_list, 'N', 'VAE', 'separate_flex64', 'inf_False_', 'latents'],\n",
    "        'faeLVM-s' : [N_list, 'N', 'VAE', 'shared_flex', 'inf_False_', 'latents'],\n",
    "        'faeLVM-b' : [N_list, 'N', 'VAE', 'bump', 'inf_False_', 'latents']\n",
    "    }\n",
    "    \n",
    "    params3 = {\n",
    "        #'mGP-g' : [T_list, 'T', 'mGP', 'orig', '', 'LLH'],\n",
    "        'i-faeLVM-n' : [T_list, 'T', 'VAE', 'separate_flex64', 'inf_True_', 'LLH'],\n",
    "        'i-faeLVM-s' : [T_list, 'T', 'VAE', 'shared_flex', 'inf_True_', 'LLH'],\n",
    "        'i-faeLVM-b' : [T_list, 'T', 'VAE', 'bump', 'inf_True_', 'LLH'],\n",
    "        'faeLVM-n' : [T_list, 'T', 'VAE', 'separate_flex64', 'inf_False_', 'LLH'],\n",
    "        'faeLVM-s' : [T_list, 'T', 'VAE', 'shared_flex', 'inf_False_', 'LLH'],\n",
    "        'faeLVM-b' : [T_list, 'T', 'VAE', 'bump', 'inf_False_', 'LLH']\n",
    "    }\n",
    "    \n",
    "    params4 = {\n",
    "        'i-faeLVM-n' : [T_list, 'T', 'VAE', 'separate_flex64', 'inf_True_', 'latents'],\n",
    "        'i-faeLVM-s' : [T_list, 'T', 'VAE', 'shared_flex', 'inf_True_', 'latents'],\n",
    "        'i-faeLVM-b' : [T_list, 'T', 'VAE', 'bump', 'inf_True_', 'latents'],\n",
    "        'faeLVM-n' : [T_list, 'T', 'VAE', 'separate_flex64', 'inf_False_', 'latents'],\n",
    "        'faeLVM-s' : [T_list, 'T', 'VAE', 'shared_flex', 'inf_False_', 'latents'],\n",
    "        'faeLVM-b' : [T_list, 'T', 'VAE', 'bump', 'inf_False_', 'latents'],\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Only i-fae models + mGP comparison (Fig4)\n",
    "    params1 = {\n",
    "        #'mGP' : [N_list, 'N', 'mGP', 'orig', '', 'rates'],\n",
    "        'faeLVM-n' : [N_list, 'N', 'VAE', 'separate_flex64', 'inf_True_', 'LLH'],\n",
    "        'faeLVM-s' : [N_list, 'N', 'VAE', 'shared_flex', 'inf_True_', 'LLH'],\n",
    "        'faeLVM-b' : [N_list, 'N', 'VAE', 'bump', 'inf_True_', 'LLH'],\n",
    "    }\n",
    "    \n",
    "    params2 = {\n",
    "        'faeLVM-n' : [N_list, 'N', 'VAE', 'separate_flex64', 'inf_True_', 'latents'],\n",
    "        'faeLVM-s' : [N_list, 'N', 'VAE', 'shared_flex', 'inf_True_', 'latents'],\n",
    "        'faeLVM-b' : [N_list, 'N', 'VAE', 'bump', 'inf_True_', 'latents'],\n",
    "        'mGP' : [N_list, 'N', 'mGP', 'orig', '', 'latents'],\n",
    "    }\n",
    "    \n",
    "    params3 = {\n",
    "        #'mGP' : [T_list, 'T', 'mGP', 'orig', '', 'rates'],\n",
    "        'faeLVM-n' : [T_list, 'T', 'VAE', 'separate_flex64', 'inf_True_', 'LLH'],\n",
    "        'faeLVM-s' : [T_list, 'T', 'VAE', 'shared_flex', 'inf_True_', 'LLH'],\n",
    "        'faeLVM-b' : [T_list, 'T', 'VAE', 'bump', 'inf_True_', 'LLH'],\n",
    "    }\n",
    "    \n",
    "    params4 = {\n",
    "        'faeLVM-n' : [T_list, 'T', 'VAE', 'separate_flex64', 'inf_True_', 'latents'],\n",
    "        'faeLVM-s' : [T_list, 'T', 'VAE', 'shared_flex', 'inf_True_', 'latents'],\n",
    "        'faeLVM-b' : [T_list, 'T', 'VAE', 'bump', 'inf_True_', 'latents'],\n",
    "        'mGP' : [T_list, 'T', 'mGP', 'orig', '', 'latents'],\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Fig4 but without smoothing kernel in Conv1D (Appendix)\n",
    "    params1 = {\n",
    "        #'mGP' : [N_list, 'N', 'mGP', 'orig', '', 'rates'],\n",
    "        'faeLVM-n' : [N_list, 'N', 'VAE', 'separate_nosmooth', 'inf_True_', 'LLH'],\n",
    "        'faeLVM-s' : [N_list, 'N', 'VAE', 'shared_nosmooth', 'inf_True_', 'LLH'],\n",
    "        'faeLVM-b' : [N_list, 'N', 'VAE', 'bump_nosmooth', 'inf_True_', 'LLH'],\n",
    "    }\n",
    "    \n",
    "    params2 = {\n",
    "        'faeLVM-n' : [N_list, 'N', 'VAE', 'separate_nosmooth', 'inf_True_', 'latents'],\n",
    "        'faeLVM-s' : [N_list, 'N', 'VAE', 'shared_nosmooth', 'inf_True_', 'latents'],\n",
    "        'faeLVM-b' : [N_list, 'N', 'VAE', 'bump_nosmooth', 'inf_True_', 'latents'],\n",
    "        'mGP' : [N_list, 'N', 'mGP', 'orig', '', 'latents'],\n",
    "    }\n",
    "    \n",
    "    params3 = {\n",
    "        #'mGP' : [T_list, 'T', 'mGP', 'orig', '', 'rates'],\n",
    "        'faeLVM-n' : [T_list, 'T', 'VAE', 'separate_nosmooth', 'inf_True_', 'LLH'],\n",
    "        'faeLVM-s' : [T_list, 'T', 'VAE', 'shared_nosmooth', 'inf_True_', 'LLH'],\n",
    "        'faeLVM-b' : [T_list, 'T', 'VAE', 'bump_nosmooth', 'inf_True_', 'LLH'],\n",
    "    }\n",
    "    \n",
    "    params4 = {\n",
    "        'faeLVM-n' : [T_list, 'T', 'VAE', 'separate_nosmooth', 'inf_True_', 'latents'],\n",
    "        'faeLVM-s' : [T_list, 'T', 'VAE', 'shared_nosmooth', 'inf_True_', 'latents'],\n",
    "        'faeLVM-b' : [T_list, 'T', 'VAE', 'bump_nosmooth', 'inf_True_', 'latents'],\n",
    "        'mGP' : [T_list, 'T', 'mGP', 'orig', '', 'latents'],\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig1, ax1 = plt.subplots(1,1, figsize=(5,4))\n",
    "    fig2, ax2 = plt.subplots(1,1, figsize=(5,4))\n",
    "    fig3, ax3 = plt.subplots(1,1, figsize=(5,4))\n",
    "    fig4, ax4 = plt.subplots(1,1, figsize=(5,4))\n",
    "    \n",
    "    fig5, ax5 = plt.subplots(1,1, figsize=(5,2))\n",
    "    fig6, ax6 = plt.subplots(1,1, figsize=(5,2))\n",
    "    fig7, ax7 = plt.subplots(1,1, figsize=(20,20))\n",
    "    \n",
    "    rank_list = np.zeros((len(params1.keys()), len(N_list), 20))\n",
    "    cnt = 0\n",
    "    for key, val in params1.items():\n",
    "        means, varis, dgf = return_plot_list(*val)\n",
    "        if val[-1] == 'LLH':\n",
    "            ax1.plot(val[0], means, '.-', linewidth=2)\n",
    "            rank_list[cnt, :, :] = np.array(varis)\n",
    "            cnt += 1\n",
    "        else:\n",
    "            ax1.errorbar(x=val[0], y=means, yerr=((np.sqrt(varis))/np.sqrt(dgf + 1)),\n",
    "                         fmt=\".-\", capsize=2, linewidth=2)\n",
    "        ax1.ticklabel_format(axis='y', style='scientific', scilimits=(0,0))\n",
    "        ax1.set_xlabel(r'$N_{train}$', fontsize=20)\n",
    "        if val[-1] == 'LLH':\n",
    "            ax1.set_ylabel('Rate pred. [NLLH]', fontsize=20)\n",
    "        else:\n",
    "            ax1.set_ylabel('Rate pred. [corr.]', fontsize=20)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.tick_params(axis='x', labelsize=15)\n",
    "        ax1.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "        #print(key, means[1], means[4], means[7])\n",
    "    \n",
    "    if val[-1] == 'LLH':\n",
    "        def rank(x, axis):\n",
    "            return np.argsort(np.argsort(x, axis=axis), axis=axis) + 1\n",
    "        #print(rank(rank_list, 0))\n",
    "        ranked_list = (np.mean(rank(rank_list, 0), axis=-1))\n",
    "        for i in range(ranked_list.shape[0]):\n",
    "            ax5.plot(val[0], ranked_list[i], '.-', linewidth=2)\n",
    "        ax5.set_yticks([1,2,3], [1,2,3], fontsize=15)\n",
    "        ax5.set_xlabel(r'$N_{train}$', fontsize=20)\n",
    "        ax5.set_ylabel('Avg. rank', fontsize=20)\n",
    "        ax5.tick_params(axis='x', labelsize=15)\n",
    "    \n",
    "    print(\"First done\")\n",
    "    labels = []\n",
    "    for key, val in params2.items():\n",
    "        means, varis, dgf = return_plot_list(*val)\n",
    "        ax3.errorbar(x=val[0], y=means, yerr=((np.sqrt(varis))/np.sqrt(dgf + 1)),\n",
    "                     fmt=\".-\", capsize=2, linewidth=2)\n",
    "        ax3.set_xlabel(r'$N_{train}$', fontsize=20)\n",
    "        ax3.set_ylabel(\"Latent pred. [GE]\", fontsize=20)\n",
    "        ax3.spines['right'].set_visible(False)\n",
    "        ax3.spines['top'].set_visible(False)\n",
    "        ax3.tick_params(axis='x', labelsize=15)\n",
    "        ax3.tick_params(axis='y', labelsize=15)\n",
    "        labels.append(key)\n",
    "        #print(key, means[1], means[4], means[7])\n",
    "        \n",
    "    print(\"Second done\")\n",
    "    \n",
    "    rank_list = np.zeros((len(params1.keys()), len(T_list), 20))\n",
    "    cnt = 0\n",
    "    for key, val in params3.items():\n",
    "        means, varis, dgf = return_plot_list(*val)\n",
    "        if val[-1] == 'LLH':\n",
    "            ax2.plot(val[0], means, '.-', linewidth=2)\n",
    "            rank_list[cnt, :, :] = np.array(varis)\n",
    "            cnt += 1\n",
    "        else:\n",
    "            ax2.errorbar(x=val[0], y=means, yerr=((np.sqrt(varis))/np.sqrt(dgf + 1)),\n",
    "                        fmt=\".-\", capsize=2, linewidth=2)\n",
    "        ax2.ticklabel_format(axis=\"y\", style=\"scientific\", scilimits=(0,0))\n",
    "        ax2.set_xscale('log', base=2)\n",
    "        ax2.set_xticks([2**7, 2**8, 2**9, 2**10, 2**11])\n",
    "        ax2.set_xlabel(r'$T_{train}$', fontsize=20)\n",
    "        ax2.set_ylabel(\"Rate pred.\", fontsize=20)\n",
    "        ax2.spines['right'].set_visible(False)\n",
    "        ax2.spines['top'].set_visible(False)\n",
    "        ax2.tick_params(axis='x', labelsize=15)\n",
    "        ax2.tick_params(axis='y', labelsize=15)\n",
    "    \n",
    "        #print(key, means[1], means[6], means[8])\n",
    "        \n",
    "    if val[-1] == 'LLH':        \n",
    "        def rank(x, axis):\n",
    "            return np.argsort(np.argsort(x, axis=axis), axis=axis) + 1\n",
    "        #print(rank(rank_list, 0))\n",
    "        ranked_list = (np.mean(rank(rank_list, 0), axis=-1))\n",
    "        for i in range(ranked_list.shape[0]):\n",
    "            ax6.plot(val[0], ranked_list[i], '.-', linewidth=2)\n",
    "        ax6.set_xscale('log', base=2)\n",
    "        ax6.set_xticks([2**7, 2**8, 2**9, 2**10, 2**11])\n",
    "        ax6.set_yticks([1,2,3], [1,2,3], fontsize=15)\n",
    "        ax6.set_xlabel(r'$T_{train}$', fontsize=20)\n",
    "        ax6.set_ylabel('Avg. rank', fontsize=20)\n",
    "        ax6.tick_params(axis='x', labelsize=15)\n",
    "         \n",
    "    print(\"Third done\")\n",
    "        \n",
    "    for key, val in params4.items():\n",
    "        means, varis, dgf = return_plot_list(*val)\n",
    "        ax4.errorbar(x=val[0], y=means, yerr=((np.sqrt(varis))/np.sqrt(dgf + 1)),\n",
    "                    fmt=\".-\", capsize=2, linewidth=2)\n",
    "        ax4.set_xscale('log', base=2)\n",
    "        ax2.set_xticks([2**7, 2**8, 2**9, 2**10, 2**11])\n",
    "        ax4.set_xlabel(r'$T_{train}$', fontsize=20)\n",
    "        ax4.set_ylabel(\"Latent pred.\", fontsize=20)\n",
    "        ax4.spines['right'].set_visible(False)\n",
    "        ax4.spines['top'].set_visible(False)\n",
    "        ax4.tick_params(axis='x', labelsize=15)\n",
    "        ax4.tick_params(axis='y', labelsize=15)\n",
    "        \n",
    "        #print(key, means[1], means[6], means[8])\n",
    "    \n",
    "    print(\"Fourth done\")\n",
    "    \n",
    "    fig1.tight_layout()\n",
    "    fig2.tight_layout()\n",
    "    fig3.tight_layout()\n",
    "    fig4.tight_layout()\n",
    "    fig5.tight_layout()\n",
    "    fig6.tight_layout()\n",
    "    \n",
    "    #fig1.savefig(time.strftime(\"./plots/%Y-%m-%d-\") + \"Fig2a_1_ns\" + \".pdf\")\n",
    "    #fig2.savefig(time.strftime(\"./plots/%Y-%m-%d-\") + \"Fig2a_2_ns\" + \".pdf\")\n",
    "    #fig3.savefig(time.strftime(\"./plots/%Y-%m-%d-\") + \"Fig2a_3_ns\" + \".pdf\")\n",
    "    #fig4.savefig(time.strftime(\"./plots/%Y-%m-%d-\") + \"Fig2a_4_ns\" + \".pdf\")\n",
    "    #fig5.savefig(time.strftime(\"./plots/%Y-%m-%d-\") + \"Fig2a_5_ns\" + \".pdf\")\n",
    "    #fig6.savefig(time.strftime(\"./plots/%Y-%m-%d-\") + \"Fig2a_6_ns\" + \".pdf\")\n",
    "    \n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    # alpha=0.3 diffuse, alpha=1 solid\n",
    "    patches = [mpatches.Patch(color=colors[i], label=labels[i], alpha=1) for i in range(len(params2.keys()))]\n",
    "    ax7.legend(handles=patches, labels=labels, loc='upper center', bbox_to_anchor=(0.5, -0.5), edgecolor='black',\n",
    "               fancybox=True, shadow=False, ncol=len(params2.keys()), fontsize=15)\n",
    "    fig7.tight_layout()\n",
    "    #fig7.savefig(time.strftime(\"./plots/%Y-%m-%d-\") + \"Fig2a_legend\" + \".pdf\")    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_check():    \n",
    "    N_list = [10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "    T_list = [75, 100, 150, 200, 300, 400, 500, 750, 1000, 2500]\n",
    "        \n",
    "    # MLP VAE as well\n",
    "    params1 = {\n",
    "        'faeLVM-b' : [N_list, 'N', 'VAE', 'bump', 'inf_False_', 'LLH'],\n",
    "        'mlpVAE' : [N_list, 'N', 'VAE', 'shared_mlp', 'inf_False_', 'LLH']\n",
    "    }\n",
    "    params3 = {\n",
    "        'faeLVM-n' : [T_list, 'T', 'VAE', 'separate_flex64', 'inf_True_', 'latents'],\n",
    "        'faeLVM-s' : [T_list, 'T', 'VAE', 'shared_flex', 'inf_True_', 'latents'],\n",
    "        'faeLVM-b' : [T_list, 'T', 'VAE', 'bump', 'inf_True_', 'latents'],\n",
    "        'mGP' : [T_list, 'T', 'mGP', 'orig', '', 'latents'],\n",
    "        'VAE' : [T_list, 'T', 'VAE', 'separate_mlp', 'inf_False_', 'latents'],\n",
    "    }\n",
    "    params2 = {\n",
    "        'faeLVM-n' : [N_list, 'N', 'VAE', 'separate_flex64', 'inf_True_', 'latents'],\n",
    "        'faeLVM-s' : [N_list, 'N', 'VAE', 'shared_flex', 'inf_True_', 'latents'],\n",
    "        'faeLVM-b' : [N_list, 'N', 'VAE', 'bump', 'inf_True_', 'latents'],\n",
    "        'mGP' : [N_list, 'N', 'mGP', 'orig', '', 'latents'],\n",
    "        'VAE' : [N_list, 'N', 'VAE', 'separate_mlp', 'inf_False_', 'latents'],\n",
    "    }\n",
    "     \n",
    "    labels=[]\n",
    "    fig2, ax2 = plt.subplots(1,1, figsize=(5,4))\n",
    "    fig3, ax3 = plt.subplots(1,1, figsize=(5,4))\n",
    "    fig7, ax7 = plt.subplots(1,1, figsize=(20,20))\n",
    "    for key, val in params2.items():\n",
    "        means, varis, dgf = return_plot_list(*val)\n",
    "        ax2.errorbar(x=val[0], y=means, yerr=((np.sqrt(varis))/np.sqrt(dgf + 1)),\n",
    "                     fmt=\".-\", capsize=2, linewidth=2)\n",
    "        ax2.set_xlabel(r'$N_{train}$', fontsize=20)\n",
    "        ax2.set_ylabel(\"Latent pred. [GE]\", fontsize=20)\n",
    "        ax2.spines['right'].set_visible(False)\n",
    "        ax2.spines['top'].set_visible(False)\n",
    "        ax2.tick_params(axis='x', labelsize=15)\n",
    "        ax2.tick_params(axis='y', labelsize=15)\n",
    "        #labels.append(key)\n",
    "        \n",
    "    for key, val in params3.items():\n",
    "        means, varis, dgf = return_plot_list(*val)\n",
    "        ax3.errorbar(x=val[0], y=means, yerr=((np.sqrt(varis))/np.sqrt(dgf + 1)),\n",
    "                    fmt=\".-\", capsize=2, linewidth=2)\n",
    "        ax3.set_xscale('log', base=2)\n",
    "        ax3.set_xticks([2**7, 2**8, 2**9, 2**10, 2**11])\n",
    "        ax3.set_xlabel(r'$T_{train}$', fontsize=20)\n",
    "        ax3.set_ylabel(\"Latent pred.\", fontsize=20)\n",
    "        ax3.spines['right'].set_visible(False)\n",
    "        ax3.spines['top'].set_visible(False)\n",
    "        ax3.tick_params(axis='x', labelsize=15)\n",
    "        ax3.tick_params(axis='y', labelsize=15)\n",
    "        labels.append(key)    \n",
    "    \n",
    "    fig2.tight_layout()\n",
    "    fig3.tight_layout()\n",
    "    \n",
    "    #fig2.savefig(time.strftime(\"./plots/%Y-%m-%d-\") + \"Fig3_1reb\" + \".pdf\")\n",
    "    #fig3.savefig(time.strftime(\"./plots/%Y-%m-%d-\") + \"Fig3_2reb\" + \".pdf\")\n",
    "    \n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    # alpha=0.3 diffuse, alpha=1 solid\n",
    "    patches = [mpatches.Patch(color=colors[i], label=labels[i], alpha=1) for i in range(len(params3.keys()))]\n",
    "    ax7.legend(handles=patches, labels=labels, loc='upper center', bbox_to_anchor=(0.5, -0.5), edgecolor='black',\n",
    "               fancybox=True, shadow=False, ncol=len(params3.keys()), fontsize=15)\n",
    "    fig7.tight_layout()\n",
    "    #fig7.savefig(time.strftime(\"./plots/%Y-%m-%d-\") + \"Fig3_3reb\" + \".pdf\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\kdais\\\\prog\\\\4222_understanding_neural_coding_on-Supplementary Material\\\\ICLR\\\\results\\\\fig2_stats_peakrate_0.5_VAE_separate_flex64_inf_True_N_10.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-37a7a091fbc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvae_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-555fc23da08d>\u001b[0m in \u001b[0;36mvae_check\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mfig7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max7\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mmeans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvaris\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdgf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_plot_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         ax2.errorbar(x=val[0], y=means, yerr=((np.sqrt(varis))/np.sqrt(dgf + 1)),\n\u001b[0;32m     32\u001b[0m                      fmt=\".-\", capsize=2, linewidth=2)\n",
      "\u001b[1;32m<ipython-input-2-2ae7ef263314>\u001b[0m in \u001b[0;36mreturn_plot_list\u001b[1;34m(scale_num_list, scaling_type, model_type, feature_type, vae_inference, rate_or_latents, n_sims)\u001b[0m\n\u001b[0;32m     60\u001b[0m                 model_type, feature_type, vae_inference, scaling_type, scale_num))\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m                 \u001b[0mstats_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\kdais\\\\prog\\\\4222_understanding_neural_coding_on-Supplementary Material\\\\ICLR\\\\results\\\\fig2_stats_peakrate_0.5_VAE_separate_flex64_inf_True_N_10.pkl'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vae_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_fig2A()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
